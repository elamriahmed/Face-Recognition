{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QPushButton, QFileDialog\n",
    "from pathlib import Path\n",
    "from imutils import face_utils\n",
    "import PIL.Image\n",
    "\n",
    "# Load pre-trained models\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "pose_predictor_68_point = dlib.shape_predictor(\"pretrained_model/shape_predictor_68_face_landmarks.dat\")\n",
    "face_encoder = dlib.face_recognition_model_v1(\"pretrained_model/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "pose_predictor_5_point = dlib.shape_predictor(\"pretrained_model/shape_predictor_5_face_landmarks.dat\")\n",
    "\n",
    "\n",
    "def transform(image, face_locations):\n",
    "    coord_faces = []\n",
    "    for face in face_locations:\n",
    "        rect = face.top(), face.right(), face.bottom(), face.left()\n",
    "        coord_face = max(rect[0], 0), min(rect[1], image.shape[1]), min(rect[2], image.shape[0]), max(rect[3], 0)\n",
    "        coord_faces.append(coord_face)\n",
    "    return coord_faces\n",
    "\n",
    "def detect_and_crop_faces(image, upscale_factor=1, min_face_size=(30, 30)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector(gray, upscale_factor)\n",
    "    cropped_faces = []\n",
    "\n",
    "    for face in faces:\n",
    "        (x, y, w, h) = (face.left(), face.top(), face.width(), face.height())\n",
    "        if w >= min_face_size[0] and h >= min_face_size[1]:\n",
    "            cropped_face = image[y:y+h, x:x+w]\n",
    "            cropped_faces.append(cropped_face)\n",
    "    \n",
    "    return cropped_faces\n",
    "\n",
    "def encode_face(image):\n",
    "    if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif image.shape[2] == 4:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    elif image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_locations = face_detector(image, 1)\n",
    "    face_encodings_list = []\n",
    "    landmarks_list = []\n",
    "\n",
    "    for face_location in face_locations:\n",
    "        shape = pose_predictor_68_point(image, face_location)\n",
    "        face_encodings_list.append(np.array(face_encoder.compute_face_descriptor(image, shape, num_jitters=1)))\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        landmarks_list.append(shape)\n",
    "\n",
    "    face_locations = transform(image, face_locations)\n",
    "    return face_encodings_list, face_locations, landmarks_list\n",
    "\n",
    "def easy_face_reco(frame, known_face_encodings, known_face_names):\n",
    "    rgb_small_frame = frame[:, :, ::-1]\n",
    "    # ENCODING FACE\n",
    "    face_encodings_list, face_locations_list, landmarks_list = encode_face(rgb_small_frame)\n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings_list:\n",
    "        if len(face_encoding) == 0:\n",
    "            return np.empty((0))\n",
    "        # CHECK DISTANCE BETWEEN KNOWN FACES AND FACES DETECTED\n",
    "        vectors = np.linalg.norm(known_face_encodings - face_encoding, axis=1)\n",
    "        tolerance = 0.55\n",
    "\n",
    "        # Initialize lists to collect matching indices and names\n",
    "        match_indices = []\n",
    "        names = []\n",
    "\n",
    "        # Populate match_indices with indices where vectors <= tolerance\n",
    "        for idx, vector in enumerate(vectors):\n",
    "            if vector <= tolerance:\n",
    "                match_indices.append(idx)\n",
    "\n",
    "        # Gather names corresponding to match_indices\n",
    "        for idx in match_indices:\n",
    "            names.append(known_face_names[idx])\n",
    "\n",
    "        # Join names into a single string separated by commas\n",
    "        if names:\n",
    "            name = \", \".join(names)\n",
    "        else:\n",
    "            name = \"Inconnu\"\n",
    "        face_names.append(name)\n",
    "\n",
    "    # Draw rectangles and names on the face locations\n",
    "    for (top, right, bottom, left), name in zip(face_locations_list, face_names):\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, (left, bottom - 30), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "        cv2.putText(frame, name, (left + 2, bottom - 2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "\n",
    "    # Draw landmarks on the faces\n",
    "    for shape in landmarks_list:\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(frame, (x, y), 1, (255, 0, 255), -1)\n",
    "\n",
    "class FacialRecogApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "        self.known_face_encodings = []\n",
    "        self.known_face_names = []\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Reconnaissance Faciale')\n",
    "        self.layout = QVBoxLayout()\n",
    "        self.label = QLabel('Cliquez sur les boutons pour charger les visages connus et une image à analyser')\n",
    "        self.layout.addWidget(self.label)\n",
    "        self.load_faces_button = QPushButton('Charger les visages connus')\n",
    "        self.load_faces_button.clicked.connect(self.load_known_faces)\n",
    "        self.layout.addWidget(self.load_faces_button)\n",
    "        self.load_image_button = QPushButton('Charger une image à analyser')\n",
    "        self.load_image_button.clicked.connect(self.load_image)\n",
    "        self.layout.addWidget(self.load_image_button)\n",
    "        self.crop_faces_button = QPushButton('Détecter et Recadrer Visages')\n",
    "        self.crop_faces_button.clicked.connect(self.crop_faces)\n",
    "        self.layout.addWidget(self.crop_faces_button)\n",
    "        self.setLayout(self.layout)\n",
    "\n",
    "    def load_known_faces(self):\n",
    "        face_to_encode_path = QFileDialog.getExistingDirectory(self, 'Sélectionner le répertoire des visages connus')\n",
    "        if face_to_encode_path:\n",
    "            print('[INFO] Importation des visages...')\n",
    "            files = list(Path(face_to_encode_path).glob('*'))\n",
    "            self.known_face_names = [file.stem for file in files]\n",
    "            self.known_face_encodings = []\n",
    "\n",
    "            for file_ in files:\n",
    "                image = PIL.Image.open(file_)\n",
    "                image = np.array(image)\n",
    "                face_encoded = encode_face(image)[0][0]\n",
    "                self.known_face_encodings.append(face_encoded)\n",
    "\n",
    "            print(f'[INFO] Chargé {len(self.known_face_names)} visages connus.')\n",
    "            self.label.setText(f'{len(self.known_face_names)} visages connus chargés.')\n",
    "\n",
    "    def load_image(self):\n",
    "        image_path, _ = QFileDialog.getOpenFileName(self, 'Sélectionner une image à analyser')\n",
    "        if image_path:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"[ERROR] Unable to load image {image_path}\")\n",
    "                return\n",
    "\n",
    "            print('[INFO] Détection...')\n",
    "            if not self.known_face_encodings:\n",
    "                print(\"[WARNING] Aucun visage connu chargé.\")\n",
    "                self.label.setText('Aucun visage connu chargé.')\n",
    "                return\n",
    "\n",
    "            image = preprocess_image(image)\n",
    "            easy_face_reco(image, self.known_face_encodings, self.known_face_names)\n",
    "            cv2.imshow('App de reconnaissance faciale', image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            print('[INFO] Arrêt du système...')\n",
    "\n",
    "    def crop_faces(self):\n",
    "        image_path, _ = QFileDialog.getOpenFileName(self, 'Sélectionner une image d\\'ID à détecter et recadrer')\n",
    "        if image_path:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"[ERROR] Unable to load image {image_path}\")\n",
    "                return\n",
    "\n",
    "            image = preprocess_image(image)\n",
    "            cropped_faces = detect_and_crop_faces(image)\n",
    "\n",
    "            # Display cropped faces\n",
    "            for i, face in enumerate(cropped_faces):\n",
    "                cv2.imshow(f'Cropped Face {i+1}', face)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "            print('[INFO] Détection et recadrage terminés.')\n",
    "\n",
    "def preprocess_image(image):\n",
    "        # Perform face recognition and display the result\n",
    "    easy_face_reco(image, known_face_encodings, known_face_names)\n",
    "\n",
    "    return image  # Add any preprocessing steps here if needed\n",
    "\n",
    "def main():\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = FacialRecogApp()\n",
    "    ex.show()\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
